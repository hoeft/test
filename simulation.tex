\chapter{Simulations} \label{ch:simulation}

In Chapter \ref{ch:model} we discussed different configurations of our pdf's $f$ and $g$, and the censoring model $m$. We will now see simulation studies corresponding to some of those setups. In Section \ref{sec: computational_aspects} we will detail, how those simulations are calculated. The remaining sections of this chapter will show simulations for different setups of $f$, $g$ and $m$.

\section{Computational Aspects}\label{sec: computational_aspects}
Assume that we have $(Z_i, \delta_i)_{i\leq n}$ is a sample in the sense of RCM. Define the target value 
$$\theta^* := \int_{0}^{\tau_H}\int_{0}^{\tau_H} \phi(s,t) F(ds)F(dt)$$
and denote $U_n$ an estimator for $\theta^*$. In the following, we will estimate the above for different kernels $\phi$ under different censoring models $m$ for $F_n^{se}$. For the simulation, one chooses first an appropriate censoring model $m$ in connection with the compatible distribution for $X$ and/or $Y$. The kernel $\phi$ can be chosen separately. Then the Maximum Likelihood estimate for $\hat\theta_n$ is calculated. Afterwards, the Kaplan-Meier and the semiparametric weights are calculated, using the following formulas
$$W_{i,n}^{se} = F_n^{se}(Z_{i:n}) - F_n^{se}(Z_{i-1:n}) = \frac{m(Z_{i:n},\hat\theta_n)}{n-i+1} \prod\limits_{k=1}^{i-1}\left[1-\frac{m(Z_{k:n},\hat\theta_n)}{n-k+1}\right]$$
and 
$$W_{i,n}^{km} = F_n^{km}(Z_{i:n}) - F_n^{km}(Z_{i-1:n}) = \frac{\delta_{[i:n]}}{n-i+1} \prod\limits_{k=1}^{i-1}\left[1-\frac{\delta_{[k:n]}}{n-k+1}\right]$$
respectively. Now the normalized versions of the Kaplan-Meier and the semiparametric U-statistics can be calculated as
$$U_n^{se} = \doublesum\limits_{1\leq i < j \leq n} \phi(Z_{i:n}, Z_{j:n}) W_{i,n}^{se} W_{j,n}^{se}$$
and 
$$U_n^{km} = \doublesum\limits_{1\leq i < j \leq n} \phi(Z_{i:n}, Z_{j:n}) W_{i,n}^{km} W_{j,n}^{km}$$
%\\
\\
As kernel for the following simulation studies, we choose 
$$\phi(x_1,x_2) = \frac{1}{2} (x_1 - x_2)^2\mdot$$
Hence we are estimating the sample variance, as pointed out in example \ref{ex:phi}. The semiparametric and the Kaplan-Meier estimates of $\theta^*$ will be denoted as $\sigma_{n}^{se}$ and $\sigma_{n}^{km}$. Each simulation is repeated $M = 100$ times for different samples of size $n$. Let $((Z_i, \delta_i)_{i\leq n})_{j\leq M}$ be the collection of $M$ independent RCM samples generated and let $\sigma_n \in \{\sigma_n^{se}, \sigma_n^{km}\}$. We will write $\sigma_{n,j}$ estimate of $\theta^*$ based on sample $((Z_i, \delta_i)_{i\leq n})_j$ for $j=1,\dots,M$. The Bias of $\sigma_n$ will be calculated by the following formula
$$Bias(\sigma_n) = \frac{1}{M}\sum_{j=1}^{M}(\sigma_{n,j} - \theta^*)\mdot$$
For the Variance of $\sigma_n$ we use
$$Var(\sigma_n) = \frac{1}{M-1}\sum_{j=1}^{M}(\sigma_{n,j} - \bar\sigma_M)^2 \quad\text{ with }\quad \bar\sigma_M = \frac{1}{M} \sum_{j=1}^{M} \sigma_{n,j}\mdot$$
The mean squared error (MSE) will be estimated by
$$MSE(\sigma_n) = \frac{1}{M}\sum_{j=1}^{M}(\sigma_{n,j} - \theta^*)^2\mdot$$ 
Additionally, we will calculate the average proportion of uncensored observations by
$$\bar c = \frac{1}{M} \sum_{j=1}^{M} c_{n,j} \quad\textrm{ with } \quad c_{n,j} = \frac{1}{n} \sum_{i=1}^{n} \delta_{[i:n+1]}\mdot$$
Furthermore we will calculate quantiles of $F_n^{km}$ and $F_n^{se}$, by
$$q_n^{se}(p) = \inf\{t \in \R_+| F_n^{se}(t) \geq p\}$$
and
$$q_n^{se}(p) = \inf\{t \in \R_+| F_n^{se}(t) \geq p\}\mcomma$$
respectively. In order to get information about the underlying estimates $F_n^{se}$ and $F_n^{km}$ of the true \df\ $F$, we will calculate the Bias, variance and MSE for $q_n^{se}(p)$ and $q_n^{km}(p)$ as well. The simulation results will be displayed in two tables. One table contains bias, variance and MSE of $\sigma_n^{se}$ and $\sigma_{n}^{km}$. The other table shows the bias and MSE of $q_n^{se}(p)$ and $q_n^{km}(p)$ for $p\in\{0.25, 0.5, 0.75\}$. The results are also illustrated by a figure at the end of each section. The left image shows the \textbf{squared} Bias, variance and MSE for $\sigma_n^{se}$ and $\sigma_n^{km}$. The right image displays the MSE of $q_n^{se}(p)$ and $q_n^{km}(p)$ for $p\in\{0.25, 0.5, 0.75\}$.
%
%
%
\section{Simulation 1} \label{sec:sim_expexp}
Suppose $X \sim Exp(\alpha)$ and $Y\sim Exp(\beta)$. Then we have
$$m(z,\theta) = \frac{\alpha}{\alpha + \beta} = \theta\mdot$$
is constant in this case. Hence we are in the situation of proportional hazards model, as described in \ref{ex:intro_phm}.\\
\\
For this simulation, we chose $\alpha = 2$ and $\beta = 1$. The target value was here
$$Var(X) = \frac{1}{\alpha^2}=\frac{1}{4}\mdot$$
For this simulation we will calculate the Cheng-Lin estimate (see Example \ref{ex:intro_phm}) of $Var(X)$, namely $\sigma_n^{cl}$, additionally to $\sigma_n^{se}$ and $\sigma_n^{km}$. We calculate  $\sigma_n^{cl}$ as
$$\doublesum\limits_{1\leq i < j \leq n} \phi(Z_{i:n}, Z_{j:n}) W_{i,n}^{cl} W_{j,n}^{cl}$$
where
$$W_{i,n}^{cl} = \left[1-\left(\frac{n-i}{n-i+1}\right)^{c_n}\right] \times \prod_{k=1}^{i-1}\left[\frac{n-k}{n-k+1}\right]^{c_n}\mdot$$
Bias, variance, MSE and quantiles will be calculated and displayed for $\sigma_n^{cl}$ in Table \ref{tab:res_expexp1} and Table \ref{tab:res_expexp2}, in order to compare the values with corresponding ones for $\sigma_n^{se}$ and $\sigma_n^{km}$. We expect that $\sigma_n^{se}$ and $\sigma_n^{cl}$ will show similar results, because of \cite{dikta2000strong}, page 3. Figure \ref{fig:dens_expexp} shows the pdf's $f$ and $g$, as well as the censoring model.
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.65\textwidth]{./figures/exp_exp_dens}
	\end{center}
	\caption{Probability density functions $f$, $g$ and censoring model $m$ for Simulation 1.}
	\label{fig:dens_expexp}
\end{figure}
 Under this setup we have $m(\cdot, \theta) = 2/3$. Since the censoring model is constant, we can expect that censoring will be occurring at the same rate over the whole domain.
\begin{table}[h!]
	\begin{center}
		%run(n = c(500,1000,5000), theta1 = c(2,1), theta2 = c(1,1))
		\begin{tabular}{| l || c | c | c |}
			\hline
			&       $n=100$   &    $n=500$    &    $n=1000$\\
			\hline
			\hline
			%			$\sigma_n^{se}$ & 0.191866 & 0.218288 & 0.229699\\
			%			$\sigma_n^{km}$ & 0.180889 & 0.213888 & 0.223222\\
			%			$\sigma_n^{cl}$ & 0.219298 & 0.232127 & 0.241302\\
			%			\hline
			$Bias(\sigma_n^{se})$ & -0.058134 & -0.031712 & -0.020301\\
			$Bias(\sigma_n^{km})$ & -0.069111 & -0.036112 & -0.026778\\
			$Bias(\sigma_n^{cl})$ & -0.030702 & -0.017873 & -0.008698\\
			\hline
			$Var(\sigma_n^{se})$ & 0.005358 & 0.002032 & 0.001306\\
			$Var(\sigma_n^{km})$ & 0.009067 & 0.002828 & 0.001783\\
			$Var(\sigma_n^{cl})$ & 0.007999 & 0.002731 & 0.001645\\
			\hline
			$MSE(\sigma_n^{se})$ & 0.008737 & 0.003038 & 0.001719\\
			$MSE(\sigma_n^{km})$  & 0.013843 & 0.004132 & 0.0025\\
			$MSE(\sigma_n^{cl})$ & 0.008942 & 0.003051 & 0.001721\\
			\hline
			\hline
			$\bar c$  &0.6646 & 0.66456 & 0.66831\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Results for Simulation 1.}
	\label{tab:res_expexp1}
\end{table}\\
%
Table \ref{tab:res_expexp1} shows, that bias, variance and MSE are decreasing to zero for all three estimators. $\sigma_n^{se}$ and $\sigma_n^{cl}$ are performing clearly better than $\sigma_n^{km}$ under this setup, while $\sigma_n^{se}$ and $\sigma_n^{cl}$ show roughly the same behavior, as we expected in the beginning of this section. 
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.85\textwidth]{./figures/expexp_mse2}
	\end{center}
	\caption{Results for Simulation 1. left: bias, variance and MSE for $\sigma_n^{se}$ and $\sigma_n^{km}$. right: MSE for $q_n^{se}$ and $q_n^{km}$.}
	\label{fig:mse_expexp}
\end{figure}
%
\clearpage
%
Figure \ref{fig:mse_expexp} indicates that the gain in efficiency of $\sigma_n^{se}$ and $\sigma_n^{cl}$ versus $\sigma_n^{km}$ is greater for smaller sample sizes. Moreover we can see that the gain in efficiency for $\sigma_{n}^{se}$ and $\sigma_n^{cl}$ is more related to the variance, than to the bias.\\
\\
The Quantiles are estimated quite well under this setup, though they are mainly underestimated by a small amount. 
%
\begin{table}[h!]
	\begin{center}
		%run(n = c(500,1000,5000), theta1 = c(2,1), theta2 = c(1,1))
		\begin{tabular}{| l || c | c | c || c | c | c |}
			\hline
			&       $n=100$   &    $n=500$    &    $n=1000$ &       $n=100$   &    $n=500$    &    $n=1000$\\
			\cline{2-7}
			& \multicolumn{3}{c||}{$Bias$} &\multicolumn{3}{c|}{$MSE$}\\
			\hline
			\hline
			$q^{se}_n(0.25) $  & -0.010451 & -0.00343 & -0.003073  & 0.000733 & 0.000149 & 0.000079\\
			$q^{km}_n(0.25) $  & -0.003812 & -0.001652 & -0.002311  & 0.000981 & 0.00018 & 0.000088\\
			$q^{cl}_n(0.25) $  & -0.006674 & -0.00119 & -0.001907  & 0.000736 & 0.000137 & 0.000076\\
			\hline
			$q^{se}_n(0.5) $  & -0.010855 & -0.001042 & -0.003221  & 0.002899 & 0.000453 & 0.000283\\
			$q^{km}_n(0.5)$  & -0.004584 & -0.000072 & -0.001659  & 0.003342 & 0.000572 & 0.000316\\
			$q^{cl}_n(0.5)$  & -0.008816 & 0.000637 & -0.002438  & 0.002894 & 0.000465 & 0.000281\\
			\hline
			$q^{se}_n(0.75)$  & -0.012331 & 0.00739 & -0.003152  & 0.008363 & 0.001764 & 0.001012\\
			$q^{km}_n(0.75)$  & -0.014291 & 0.007734 & -0.003026  & 0.010265 & 0.001963 & 0.001175\\
			$q^{cl}_n(0.75)$  & -0.019053 & 0.003871 & -0.004781  & 0.008135 & 0.00166 & 0.001006\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Results for estimated quantiles of Simulation 1.}
	\label{tab:res_expexp2}
\end{table}
%
%\clearpage
%
%
%
\section{Simulation 2} \label{sec:sim_weiwei}

Let $X \sim Weibull(\alpha_1, \beta_1)$ and  $X \sim Weibull(\alpha_2, \beta_2)$.
%$$f(z) = \alpha_1\beta_1 (\alpha_1 z)^{\beta_1-1}\exp\left(-(\alpha_1 z)^{\beta_1}\right)$$
%$$g(z) = \alpha_2\beta_2 (\alpha_2 z)^{\beta_2-1}\exp\left(-(\alpha_2 z)^{\beta_2}\right)$$
Then we obtain for the censoring model 
$$m(z,\theta) = \frac{1}{1+\theta_1 z^{\theta_2}} \textrm{ with } \theta = \left(\frac{\alpha_2^{\beta_2}\beta_2}{\alpha_1^{\beta_1}\beta_1}, \beta_2 - \beta_1\right)$$
%
For the simulation below we chose $\alpha_1 = 2$, $\alpha_2 = 1$, $\beta_1 = 1.2$ and $\beta_2 = 1$. The target value was here
$$Var(X) = 0.192843\mdot$$
Figure \ref{fig:dens_wei_wei} indicates that smaller values are censored rather than larger ones under this setup.  This is due to the increasing nature of the censoring model $m$.
%
\clearpage
%
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.65\textwidth]{./figures/wei_wei_dens}
	\end{center}
	\caption{Probability density functions $f$, $g$ and censoring model $m$ for Simulation 1.}
	\label{fig:dens_wei_wei}
\end{figure}
\noindent Table \ref{tab:res_weiwei1} shows that bias, variance and MSE are converging to zero for both estimators, as well under this setup. The semiparametric estimator is clearly more efficient than the Kaplan-Meier estimate \wrt\ the MSE. Here again, difference in variance is much larger than the difference in squared bias. 
%
\begin{table}[h!]
	\begin{center}
		%run(n = c(500,1000,5000), theta1 = c(2,1.2), theta2 = c(1,1))
		\begin{tabular}{| l || c | c | c |}
			\hline
			&       $n=100$   &    $n=500$    &    $n=1000$\\
			\hline
			\hline
%			$Var$ & 0.154936 & 0.154936 & 0.154936\\
%			$U_n^{se}$ & 0.13533 & 0.154696 & 0.158717\\
%			$U_n^km$ & 0.134849 & 0.143497 & 0.143514\\
			$Bias(\sigma_n^{se})$ & -0.019606 & -0.000239 & 0.003782\\
			$Bias(\sigma_n^{km})$ & -0.020086 & -0.011439 & -0.011422\\
			\hline
			$Var(\sigma_n^{se})$ & 0.001659 & 0.000669 & 0.000298\\
			$Var(\sigma_n^{km})$ & 0.002861 & 0.000794 & 0.000257\\
			\hline
			$MSE(\sigma_n^{se})$ & 0.002044 & 0.000669 & 0.000312\\
			$MSE(\sigma_n^{km})$ & 0.003265 & 0.000925 & 0.000388\\
			\hline
			\hline
			$\bar c$ & 0.6705 & 0.6678 & 0.66538\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Results for Simulation 2.}
	\label{tab:res_weiwei1}
\end{table}\\
%
Figure \ref{fig:mse_weiwei} shows, as before, that the gain in efficiency is greater for smaller sample sizes $n$. Again, the gain in efficiency is more severe for smaller $n$ in this simulation. We can also see that the variance is contributing more to the gain in efficiency.
%
\clearpage
%
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=0.85\textwidth]{./figures/weiwei_mse2}
	\end{center}
	\caption{Results for Simulation 2. left: bias, variance and MSE for $\sigma_n^{se}$ and $\sigma_n^{km}$. right: MSE for $q_n^{se}$ and $q_n^{km}$.}
	\label{fig:mse_weiwei}
\end{figure}
%
\noindent The Quantiles are estimated quite well under this setup, as we can see from Table \ref{tab:res_weiwei2}. As before, the quantiles are, for the most part, slightly underestimated by both estimators. Figure \ref{fig:mse_weiwei} shows that $q_n^{se}$ is performing slightly better $q_n^{km}$ here.
\begin{table}[h!]
	\begin{center}
		%run(n = c(500,1000,5000), theta1 = c(2,1.2), theta2 = c(1,1))
		\begin{tabular}{| l || c | c | c || c | c | c |}
			\hline
			&       $n=100$   &    $n=500$    &    $n=1000$ &       $n=100$   &    $n=500$    &    $n=1000$\\
			\cline{2-7}
			& \multicolumn{3}{c||}{$Bias$} &\multicolumn{3}{c|}{$MSE$}\\
			\hline
			\hline
			$q^{se}_n(0.25)$ & -0.018255 & -0.011443 & -0.011854& 0.000873 & 0.000228 & 0.000206\\
			$q^{km}_n(0.25)$ & -0.007356 & -0.000332 & -0.000922& 0.000666 & 0.000165 & 0.000079\\
			\hline
			$q^{se}_n(0.5)$ & -0.012298 & -0.011298 & -0.00798& 0.002225 & 0.000593 & 0.000263\\
			$q^{km}_n(0.5)$ & -0.006786 & -0.00582 & -0.002101 & 0.002391 & 0.000641 & 0.000215\\
			\hline
			$q^{se}_n(0.75)$ & -0.009176 & 0.000363 & 0.007358& 0.007562 & 0.001251 & 0.000744\\
			$q^{km}_n(0.75)$ & -0.015825 & -0.010461 & -0.002481 & 0.008823 & 0.001511 & 0.000705\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Results for estimated quantiles of Simulation 2.}
	\label{tab:res_weiwei2}
\end{table}
%
%
%
\section{Simulation 3} \label{sec:sim_exppar}
Let $X \sim Exp(\alpha)$ and $Y \sim Par(\beta)$. For our model $m$ we obtain in this case
$$m(z,\theta) = \frac{\alpha}{\alpha + \frac{\beta}{z}\I{z \geq \beta}}\mdot$$
Note that $m$ is \textbf{not} non-decreasing over the whole domain in this case (\cf\ Example \ref{ex:exppar}). For the following simulation we chose $\alpha = 0.5$ and $\beta = 1.2$. The target value was here
$$Var(X) = 4\mdot$$
%
%\clearpage
%
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.65\textwidth]{./figures/exppar_dens}
	\end{center}
	\caption{Probability density functions $f$, $g$ and censoring model $m$ for Simulation 3.}
	\label{fig:dens_exppar}
\end{figure}
%
Considering Figure \ref{fig:dens_exppar}, we can not expect any censored observations on $[0,\beta]$. Moreover the plot indicates that values in $[\beta,3]$ are more likely to be censored. On $[\beta,\infty)$, the censoring model is monotone increasing. This implies that smaller values are more likely to be censored than larger values.
\clearpage
\begin{table}[h!]
	\begin{center}

%run(n = c(100,500,1000), m = 100, theta = c(0.5, 1.2))
	\begin{tabular}{| l || c | c | c |}	
		\hline
		& $ n = 100 $ & $ n = 500 $ & $ n = 1000 $\\
		\hline
		\hline
%		$Var$ & 4 & 4 & 4\\
%		$U_n^{se}$ & 2.938322 & 3.574439 & 3.726535\\
%		$U_n^km$ & 2.902828 & 3.48581 & 3.681142\\
		$Bias(\sigma_n^{se})$ & -1.061678 & -0.425561 & -0.273465\\
		$Bias(\sigma_n^{km})$ & -1.097172 & -0.51419 & -0.318858\\
		\hline
		$Var(\sigma_n^{se})$ & 2.828115 & 0.852244 & 0.362266\\
		$Var(\sigma_n^{km})$ & 2.991916 & 1.289473 & 0.5611\\
		\hline
		$MSE(\sigma_n^{se})$ & 3.955275 & 1.033346 & 0.437049\\
		$MSE(\sigma_n^{km})$ & 4.195703 & 1.553865 & 0.66277\\
		\hline
		\hline
		$\bar c$ & 0.6971 & 0.69704 & 0.69616\\
		\hline
	\end{tabular}
	\end{center}
	\caption{Results for simulation 3.}
	\label{tab:res_exppar1}
\end{table}
%
\noindent From Table \ref{tab:res_exppar1}, we see that the MSE values of both estimators,  $\sigma_n^{se}$ and $\sigma_n^{km}$, are substantially larger than in the previous examples, especially for $n=100$. However, the MSE values decrease considerably as $n$ increases. Figure \ref{fig:mse_exppar}, shows that the semiparametric estimator is performing better than the Kaplan-Meier estimate again, with a larger gain in efficiency for small $n$ .
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=0.8\textwidth]{./figures/exppar_mse2}
	\end{center}
	\caption{Results for Simulation 3. left: bias, variance and MSE for $\sigma_n^{se}$ and $\sigma_n^{km}$. right: MSE for $q_n^{se}$ and $q_n^{km}$.}
	\label{fig:mse_exppar}
\end{figure}
%
\clearpage
Table \ref{tab:res_exppar2} shows, that the quantiles are considerably substantially by both estimators in this case. This might be a consequence of the fact, that $m$ violates condition (A\ref{ass:m_increas}) under this setup. The large MSE values for the quantile estimates are likely to cause the much larger MSE scores of $\sigma_n^{se}$ and $\sigma_n^{km}$ for this simulation.
\begin{table}[h!]
	\begin{center}
		
		%run(n = c(100,500,1000), m = 100, theta = c(0.5, 1.2))
		\begin{tabular}{| l || c | c | c || c | c | c |}
			\hline
			&       $n=100$   &    $n=500$    &    $n=1000$ &       $n=100$   &    $n=500$    &    $n=1000$\\
			\cline{2-7}
			& \multicolumn{3}{c||}{$Bias$} &\multicolumn{3}{c|}{$MSE$}\\
			\hline
			\hline
			$q^{se}_n(0.25)$ & -0.946058 & -0.953076 & -0.948244& 0.906359 & 0.910549 & 0.900719\\
			$q^{km}_n(0.25)$ & -0.946058 & -0.953076 & -0.948244& 0.906359 & 0.910549 & 0.900719\\
			\hline
			$q^{se}_n(0.5)$ & -0.761661 & -0.763693 & -0.751274& 0.615678 & 0.590391 & 0.568224\\
			$q^{km}_n(0.5)$ & -0.756513 & -0.758938 & -0.748412 & 0.610569 & 0.583492 & 0.564373\\
			\hline
			$q^{se}_n(0.75)$ & -1.144379 & -1.062969 & -1.04613 & 1.400626 & 1.158716 & 1.109287\\
			$q^{km}_n(0.75)$ & -1.164122 & -1.088963 & -1.0535 & 1.506353 & 1.222739 & 1.130558\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Results for estimated quantiles of Simulation 3.}
	\label{tab:res_exppar2}
\end{table}
