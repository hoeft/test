\chapter{Introduction} \label{ch:introduction}
\label{sec:introduction}

% U-Statistics uncensored case
Assume that $X_1,...,X_n$ are independent and identically distributed (\iid) random variables (\rv) on $\R$ which are defined on a common probability space $(\Omega, \A, \P)$. Denote their common probability distribution function (\df) by $F$. For some $k\geq 1$ let $\phi: \R^k \longrightarrow \R$ be a symmetric Borel-measurable function. Define
\begin{equation}
\theta_F = \int ... \int \phi \prod\limits_{j=1}^k dF. 
\label{eq:0101}
\end{equation}
Examples of this kind of parameters include the expected value, variance and any higher moments of the $X$'s. One approach to estimate those integrals is given by the so called U-Statistics. To obtain this estimator we need to replace the true \df\ $F$ by the empirical \df\ $F_n$ which is defined by
$$F_n(t) = \frac{1}{n}\sum\limits_{i=1}^n \I{X_i\leq t}.$$
Now plugging $F_n$ into \eqref{eq:0101} yields
$$\int ... \int \phi \prod\limits_{j=1}^k dF_n = \frac{1}{n^k}\sum\limits_{i_1=1}^n...\sum\limits_{i_k=1}^n \phi(X_{i_1},...,X_{i_k})$$
The expression on the right hand side in the equation above is known as V-statistic. It includes repeated observations. An unbiased estimate of $\theta_F$, based on distinct observations only, can be expressed as
\begin{equation}
U_{kn}(\phi) = {n \choose k}^{-1} \sum\limits_{[n,k]} \phi(X_{i_1},...,X_{i_k})\mcomma
\label{eq:0102}
\end{equation}
where the sum iterates over all sets $\{i_1,...,i_k\}$ \st\ $ 1\leq i_1 < i_2 < ... < i_n \leq n$. We call \eqref{eq:0102} U-Statistics of order $k$. In \cite{lee1990u} it was shown, that the U-Statistics is the unbiased minimum variance estimator for \eqref{eq:0101}. Observe that for $k=2$, equation \eqref{eq:0102} simplifies to
$$U_{2n}(\phi)=\frac{2}{n(n-1)}\doublesum\limits_{1\leq i<j \leq n}\phi(X_i,X_j)$$
and we have
$$\E(U_{2n}(\phi))=\int \int \phi dF dF$$
\\
% Random Censorship Model
One of the major problems in lifetime analysis is to handle incomplete observations. The incompleteness is often caused by censoring. In this thesis we are concerned with right censored data. A framework to model this kind of data is provided by the Random Censorship Model (RCM). Here we observe data of the form $(Z_i, \delta_i), i=1,...,n$ where the $Z_i$ are the observed sample values, which might include censoring and the $\delta_i$ indicate whether the corresponding $Z_i$ was censored or not. Here the sequence $(Z_i, \delta_i), i=1,...,n$ is assumed to be independent and identically distributed (\iid). Furthermore we can write for $i=1,...,n$
$$Z_i = min(X_i,Y_i) \text{ and } \delta_i=I_{X_i\leq Y_i}$$
where $X_i$ is the true lifetime and $Y_i$ is the so called censoring time. The sequences $X_i$ and $Y_i$ are also \iid and they are assumed to be independent of each other. Throughout this work the probability distribution functions (\df) of $X$, $Y$ and $Z$ will be notated $F$, $G$ and $H$ respectively. We assume that those \df's are continuous and concentrated on $R\cap [0,\infty]$.\\

% Kaplan Meier U-Statistics
Within this framework we want to study the large sample properties of estimators of $\int\int \phi dF dF$. In particular we will be concerned with the asymptotic properties of the U-statistic defined above based on our observations $(Z_i, \delta_i)$. To do so, we need new estimates for our \df\ $F$ which are based on our observations $(Z_i, \delta_i)$ rather than the $X$'s. If there can not be any further assumptions made about the censorship, except for the RCM itself, then the commonly used estimator of $F$ is the well known product limit estimator by  \citet{kaplan1958nonparametric}. It is defined by 
$$1-\fnkm(t) = \prod_{i:Z_i\leq t}\left( \frac{n-R_{i,n}}{n-R_{i,n}+1} \right)^{\delta_i}$$
where $R_{i,n}$ denotes the rank of $Z_i$. If we now consider ordered observations, we get
$$1-\fnkm(t) = \prod_{i=1}^n\left( 1-\frac{\delta_{[i:n]}}{n-i+1} \right)^{\I{Z_{i:n}\leq t}}$$
where $Z_{1:n} \leq ... \leq Z_{n:n}$ and $\delta_{[i:n]}$ denotes the concomitant of the i-th order statistics. That means $\delta_{[i:n]}=\delta_j$ whenever $Z_{i:n}=Z_j$.\\ 
Let's go back to our integral \eqref{eq:0101} and consider the case $k=1$. The integral then becomes
\begin{equation}
\int \phi dF 
\label{eq:0103}
\end{equation}
Replacing the true $F$ in \eqref{eq:0103} by $\fnkm$ yields
$$\snkm{1}{n}(\phi):=\int_0^\infty \phi dF_n^{km}=\sum_{i=1}^n \phi(Z_{i:n}) \wnkm{i}{n}$$
where $\wnkm{i}{n}$ denotes the weight placed on $Z_{i:n}$ by $F_n^{km}$. That is\\
\begin{myarray}
 \wnkm{i}{n} &= \fnkm(Z_{i:n}) - \fnkm(Z_{i-1:n})\\
          &= \frac{\delta_{[i:n]}}{n-i+1}\prod_{j=1}^{i-1}\left( \frac{n-j}{n -j+1} \right)^{\delta_{[j:n]}}\\
\end{myarray}
It is easy to see, that the Kaplan-Meier estimator only puts mass at uncensored $Z$-values, \ie 
\[ \wnkm{i}{n} = \begin{cases} 
0 & \textrm{if } \delta_{[i:n]} = 0 \\
\frac{1}{n-i+1}\prod\limits_{k=1}^{i-1}\left[1-\frac{\delta_{[k:n]}}{n-k+1}\right] > 0 & \textrm{if } \delta_{[i:n]} = 1
\end{cases}\mdot
\]
%
The strong law of large numbers (SLLN) for $\snkm{1}{n}(\phi)$ has been established by \citet{stute1993strong}.
%
Let's now consider the case $k=2$. Define
\begin{equation*}
\snkm{2}{n}(\phi) = \doublesum\limits_{1\leq i < j \leq n} \phi(Z_{i:n}, Z_{j:n}) \wnkm{i}{n} \wnkm{j}{n}.
\end{equation*}
The above estimator will be called Kaplan-Meier U-Statistics of degree 2. Moreover we can define the normalized version of $\snkm{2}{n}(\phi)$ as
$$\unkm{2}{n}(\phi) = \frac{\snkm{2}{n}(\phi)}{\snkm{2}{n}(1)} = \frac{\doublesum\limits_{1\leq i < j \leq n} \phi(Z_{i:n}, Z_{j:n}) \wnkm{i}{n} \wnkm{j}{n}}{\doublesum\limits_{1\leq i < j \leq n} \wnkm{i}{n} \wnkm{j}{n}}\mdot$$ 
The normalizing factor $(\snkm{2}{n}(1))^{-1}$ was introduced by \cite{bose1999strong}, since the following holds true for uncensored data:
$$\frac{\wnkm{i}{n}\wnkm{j}{n}}{\doublesum\limits_{1\leq u < v \leq n}\wnkm{u}{n}\wnkm{v}{n}} = \binom{n}{2}^{-1}\textrm{.}$$ 
The strong law of large numbers for $\unkm{2}{n}$ has been established in \citet{bose1999strong}. Asymptotic distributions of this estimator have been derived in \citet{bose2002asymptotic}. \\
\\
For the semiparametric Random Censorship Model (SRCM) we make, besides the assumptions of the RCM, the further assumption that 
$$m(z) = \P(\delta=1|Z=z) = \E(\delta|Z=z)$$
belongs to some parametric family, \ie\
$$m(z) = m(z,\theta_0)$$
where $\theta_0=(\theta_{0,1},...,\theta_{0,p})\in \Theta \subset \R^p$. \\
\\
\todo{Discuss} \cite{dikta1998semiparametric}, Dikta, 2014, Asymptotic Optimality\\
\\
Now the semiparametric estimator is defined by
$$1-\fnse(t) = \prod\limits_{i:Z_i\leq t}\left(1-\frac{m(Z_i,\hat{\theta}_n)}{n-R_i+1}\right)$$
as it was introduced \citet{dikta2000strong}. Here $\hat{\theta}_n$ denotes the Maximum Likelihood Estimate (MLE) of $\theta_0$. That is, $\hat{\theta}_n$ is the maximizer of 
$$L_n(\theta)=\prod\limits_{i=1}^{n} m(Z_i,\theta)^{\delta_i}(1-m(Z_i,\theta))^{1-\delta_i}.$$
Now again by replacing the true \df\ $F$ by $\fnse$ in the integral \eqref{eq:0103} we obtain the semiparametric version of $\snkm{1}{n}$, namely
$$\snse{1}{n}(\phi)=\int_0^\infty \phi d\fnse = \sum\limits_{i=1}^n \phi(Z_{i:n})\wnse{i}{n}$$
where 
$$\wnse{i}{n} = \frac{m(Z_{i:n}, \hat{\theta}_n)}{n-i+1} \prod\limits_{j=1}^{i-1}\left(1-\frac{m(Z_{j:n}, \hat{\theta}_n)}{n-j+1}\right)$$
is the mass that $\fnse$ assigns to $Z_{i:n}$. $\wnse{i}{n}$ will be called $i$-th semiparametric weight throughout this document. The SLLN and the CLT for the semiparametric U-Statistic $\snse{1}{n}$ have been established in \citet{dikta2000strong} and \citet{dikta2005central} respectively.\\
\\
The goal of this thesis will be to study the strong law of large numbers for the semiparametric U-Statistic of degree $2$, which will be defined in the next chapter. The main statement of this thesis is contained in Theorem \ref{thm:snmn_limit} at the end of Chapter \ref{ch:identify_limit}.\\
\\
\todo{Examples for different Kernels $\phi$.}
%We can now define the semiparametric U-Statistic as
%$$\unse{1}{n}(\phi)=\frac{\snse{1}{n}(\phi)}{\snse{1}{n}(1)}=\frac{\sum_{i=1}^n \phi(Z_{i:n}) \wnse{i}{n}}{\sum_{i=1}^n \wnse{i}{n}}$$
%asd
%$$\stnse{n}(\phi)= \doublesum\limits_{1\leq i<j\leq n} \phi(Z_{i:n},Z_{j:n})\wnse{i}{n}\wnse{j}{n}$$
%and
%$$\unse{2}{n}{n}(\phi)=\frac{\stnse{n}(\phi)}{\stnse{n}(1)}=\frac{\doublesum\limits_{1\leq i<j\leq n} \phi(Z_{i:n},Z_{j:n})\wnse{i}{n}\wnse{j}{n}}{\doublesum\limits_{1\leq i<j\leq n} \wnse{i}{n}\wnse{j}{n}}$$
%
%\todo{Space for expansion. Perhaps some more about life time analysis and survival function.}
